---

---

#  D√≠a 3 ‚Äì Joins, deduplicaci√≥n y optimizaci√≥n en Spark

Hoy exploramos los **joins en Spark**, una herramienta fundamental para combinar datasets en Big Data. Adem√°s, aplicamos t√©cnicas de optimizaci√≥n como **broadcast join**, y tratamos conceptos clave como la normalizaci√≥n y deduplicaci√≥n de datos.

## üß† Conceptos clave

### üîó Tipos de joins

* **Inner Join**: Devuelve solo las filas que coinciden en ambos DataFrames.
* **Left Join / Right Join**: Devuelve todas las filas del lado izquierdo (o derecho), completando con `null` si no hay coincidencia.
* **Outer Join (Full Join)**: Devuelve todas las filas de ambos lados, uniendo por coincidencias si existen.
* **Left Anti Join**: Devuelve solo las filas del izquierdo que **no** tienen match en el derecho.
* **Semi Join**: Como un `inner join` pero sin a√±adir las columnas del lado derecho.
* **Cross Join**: Hace el **producto cartesiano**. Muy peligroso si no lo necesitas.

---

### ‚ùå ¬øQu√© es el producto cartesiano?

Un **producto cartesiano** es cuando cada fila del DataFrame izquierdo se combina con **todas** las filas del derecho.

#### Ejemplo:

Si tienes:

* DF1 con 3 filas
* DF2 con 2 filas

El resultado tendr√° 3√ó2 = **6 filas**.

Es costoso y se usa **solo si sabes lo que haces**, por ejemplo, para generar combinaciones posibles o simulaciones.

**Ev√≠talo** si puedes. Si haces un `join` sin condici√≥n (`df1.join(df2)`), Spark puede hacer uno sin darte cuenta.

---

### üöÄ Broadcast Join

En Spark, un **broadcast join** es una t√©cnica para **evitar el shuffle de datos** cuando uno de los DataFrames es muy peque√±o. Spark lo env√≠a a todos los workers.

#### Cu√°ndo usarlo:

* Cuando un DataFrame es **muy peque√±o** (regla pr√°ctica: < 10 MB)
* Cuando sabes que ese DataFrame **no crece** inesperadamente

#### ¬øC√≥mo forzarlo?

```scala
import org.apache.spark.sql.functions.broadcast

val result = broadcast(smallDF).join(largeDF, "user_id")
```

Esto fuerza a Spark a replicar `smallDF` en todos los nodos para evitar la costosa redistribuci√≥n (`shuffle`) de `largeDF`.

#### ¬øC√≥mo asegurarte de que es peque√±o?

Puedes hacer:

```scala
println(s"Size: " + smallDF.count())
```

O incluso estimar el tama√±o:

```scala
val approxSize = smallDF.rdd.map(_.toString().getBytes.length.toLong).reduce(_ + _)
println(s"Approx size in bytes: $approxSize")
```

Si el `count()` es muy bajo (< 1.000 filas) o el tama√±o estimado es < 10 MB, es buen candidato para broadcast.

---

### üßπ Limpieza y normalizaci√≥n

* `dropDuplicates()` para evitar repeticiones antes de joins
* `trim()` y `lower()` para normalizar campos tipo string
* Uso de `groupBy` y `agg` para sumarizar y ordenar datos

---

## üí° Reto pr√°ctico del d√≠a

Ten√≠amos dos ficheros:

* `users.json`: contiene usuarios con `user_id`, `name`, `age`, `country`
* `purchases.json`: contiene compras con `purchase_id`, `user_id`, `product`, `amount`, `date`

Se han realizado:

* ‚úÖ Un `inner join` para combinar usuarios y compras
* ‚úÖ Un `left anti join` para detectar usuarios sin compras
* ‚úÖ Una agregaci√≥n del **total gastado por usuario**, ordenando por importe
* ‚úÖ Una normalizaci√≥n del campo `country`
* ‚úÖ Un `broadcast join` forzado
* ‚úÖ Guardado del resultado en CSV

---

## üìÅ Estructura recomendada del proyecto

```
src/
  main/
    scala/
      com/
        morci/
          portfolio/
            Day03_Joins.scala
    resources/
      users.json
      purchases.json
day03/
  output/
    resultado.csv
```

---

## üìù Conclusi√≥n

* Aprender a elegir bien el tipo de join es esencial en procesamiento de datos.
* Broadcast puede mejorar radicalmente el rendimiento si se aplica correctamente.
* El producto cartesiano es peligroso: rev√≠salo si tu `join` explota.
* Unos pocos pasos de limpieza mejoran mucho la estabilidad del pipeline.

---
