# DÃ­a 1 â€“ Arquitectura de ejecuciÃ³n de Spark

## ğŸ¯ Objetivo

Entender cÃ³mo Spark ejecuta un trabajo, desde que tÃº escribes `.filter(...).show()` hasta que los datos realmente se procesan. Esto implica comprender:

- La jerarquÃ­a de ejecuciÃ³n: Driver â†’ Job â†’ Stage â†’ Task â†’ Executor
- QuÃ© es una transformaciÃ³n y quÃ© es una acciÃ³n
- QuÃ© es un DAG y cÃ³mo Spark lo construye
- QuÃ© es un shuffle y por quÃ© es caro
- QuÃ© son las particiones y cÃ³mo afectan al rendimiento
- CÃ³mo Spark convierte cÃ³digo Scala en un plan fÃ­sico ejecutable

## ğŸ§± 1. JerarquÃ­a de ejecuciÃ³n en Spark

Cuando lanzas una aplicaciÃ³n Spark (por ejemplo desde IntelliJ), se crea una estructura jerÃ¡rquica de ejecuciÃ³n:

- **Driver**: Proceso que lanza tu cÃ³digo y coordina todo. Vive en tu mÃ¡quina o nodo principal.
- **Job**: Se lanza cada vez que se ejecuta una **acciÃ³n** (`show`, `collect`, etc.).
- **Stage**: Un job se divide en una o mÃ¡s etapas segÃºn si hay *shuffles* (reordenaciÃ³n de datos).
- **Task**: Cada stage se divide en tareas. **Cada particiÃ³n de datos** corresponde a una **task**.
- **Executor**: Proceso distribuido que ejecuta las tasks. En local, simulado con hilos; en cluster, en mÃ¡quinas distintas.

## ğŸ” 2. Transformaciones vs Acciones

### âœ… Transformaciones
- **Lazy**: no se ejecutan inmediatamente.
- Devuelven un nuevo DataFrame o RDD.
- Solo se acumulan en un **DAG lÃ³gico**.
- Ejemplos: `select`, `filter`, `withColumn`, `map`, `join`, `groupBy`.

### âœ… Acciones
- **Disparan la ejecuciÃ³n real**.
- Devuelven un resultado real o efecto (mostrar, escribir, contarâ€¦).
- Lanzan un **job**, que genera stages y tasks.
- Ejemplos: `show`, `collect`, `count`, `first`, `write`.

### Diferencia clave:
- Una transformaciÃ³n **describe lo que quieres hacer**.
- Una acciÃ³n **dice: ahora hazlo**.

## ğŸ§® 3. Particiones

Una **particiÃ³n** es una porciÃ³n del dataset que se procesa de forma aislada por una task.

- Cada task ejecuta su lÃ³gica sobre **una particiÃ³n**.
- Puedes ver el nÃºmero de particiones con `.rdd.getNumPartitions`.
- Puedes controlarlas con:
    - `.repartition(n)` â€“ fuerza una redistribuciÃ³n total (shuffle)
    - `.coalesce(n)` â€“ reduce particiones sin shuffle (cuando es posible)

## ğŸ”„ 4. DAG: Directed Acyclic Graph

El **DAG** es la representaciÃ³n interna que Spark construye con las transformaciones encadenadas.

1. Spark construye el **DAG lÃ³gico**
2. Lo **optimiza**
3. Lo convierte en un **DAG fÃ­sico** (plan de ejecuciÃ³n con operadores reales)

Puedes ver el DAG en texto con `.explain()` o grÃ¡ficamente en la Spark UI (`http://localhost:4040`).

## ğŸ§  5. Plan lÃ³gico vs plan fÃ­sico

### Plan lÃ³gico:
- Describe *quÃ©* operaciones quieres hacer (`filter`, `select`, etc.)
- Es independiente del entorno fÃ­sico

### Plan fÃ­sico:
- Describe *cÃ³mo* se ejecutan esas operaciones
- Incluye particiones, operadores fÃ­sicos, etc.

Spark convierte el plan lÃ³gico en fÃ­sico usando el **optimizador Catalyst**.

## ğŸŒªï¸ 6. Shuffle

Un **shuffle** ocurre cuando Spark necesita **reordenar los datos entre particiones o nodos**.

- Es un proceso **costoso** que implica disco + red
- **Causa un corte en el DAG â†’ nuevo stage**

### Operaciones que causan shuffle:
- `groupBy`, `join`, `distinct`, `repartition`, `orderBy`

ğŸ’¡ Los shuffles se deben evitar o controlar: tienen gran impacto en el rendimiento.

## ğŸ“ 7. CÃ³mo resumirlo en una entrevista

> â“ â€œÂ¿QuÃ© ocurre cuando haces `df.select(...).filter(...).show()`?â€

**Respuesta pro:**  
Spark construye un DAG de transformaciones lazy. Al llegar la acciÃ³n `.show()`, lanza un job, lo divide en stages y tasks por particiÃ³n. Cada task se ejecuta en un executor. El DAG se convierte en un plan fÃ­sico mediante Catalyst, y si hay redistribuciÃ³n de datos, se genera un shuffle y se separan los stages.

---

Este resumen es la base conceptual de Spark. Dominarlo te permite optimizar, explicar bien en entrevistas y trabajar con cÃ³digo mÃ¡s predecible y escalable.